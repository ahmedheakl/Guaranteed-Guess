<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees">
    <meta name="keywords" content="GG, CISC, RISC, Transpilation, x86, ARM, RISC-V, Assembly, LLM">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="icon" type="image/png" href="static/images/gg-logo.png">


    <style>
        body {
            font-family: 'Noto Sans', sans-serif;
            font-size: 16px;
        }

        .publication-title {
            font-family: 'Castoro', serif;
        }

        .publication-authors {
            font-family: 'Noto Sans', sans-serif;
        }

        .publication-authors .author-block {
            display: inline-block;
            margin-right: 10px;
        }

        .publication-authors .author-block sup {
            font-size: 0.65rem;
            vertical-align: super;
        }

        .hero.is-light {
            background-color: #f5f5f5;
        }

        .link-block {
            display: inline-block;
            margin-right: 10px;
        }

        .external-link img {
            box-shadow: none;
        }

        .gg {
            font-weight: bold;
            color: #1565c0;
        }

        .teaser .hero-body {
            padding-top: 0;
            padding-bottom: 3rem;
        }

        .teaser {
            font-family: 'Google Sans', sans-serif;
        }

        .footer .icon-link {
            font-size: 25px;
            color: #000;
        }

        .footer .icon-link:hover {
            color: #1565c0;
        }

        .results-table {
            width: 100%;
            margin: 2em 0;
        }

        .results-table th,
        .results-table td {
            padding: 0.5em;
            text-align: center;
        }

        .results-table th {
            background-color: #f5f5f5;
            font-weight: bold;
        }

        .pipeline-image {
            max-width: 100%;
            height: auto;
            margin: 2em auto;
            display: block;
        }

        .gg-bench-image {
            max-width: 70%;
            height: auto;
            margin: 2em auto;
            display: block;
        }

        .equal-contrib {
            color: #e74c3c;
            font-weight: 600;
            font-size: 0.8rem;
            margin-top: 0.5rem;
        }
    </style>
</head>

<body>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <figure class="image is-128x128 is-inline-block mb-4">
                            <img src="static/images/gg-logo.png" alt="GG Logo">
                        </figure>
                        <h1 class="title is-1 publication-title">Guaranteed Guess: A Language Modeling Approach for
                            CISC-to-RISC Transpilation with Testing Guarantees</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/ahmed-heakl/?originalSubdomain=ae">Ahmed Heakl</a><sup>♠</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/sarim-hashmi-b10b35136/">Sarim Hashmi</a><sup>♠</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/chaimaa-abi-2555a31b3/">Chaimaa Abi</a><sup>♠</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/celine-lee-2a5743147/">Celine Lee</a><sup>♡</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/abdulrahman-mahmoud-a9206b57/">Abdulrahman Mahmoud</a><sup>♠</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>♠</sup>MBZUAI &nbsp;&nbsp; <sup>♡</sup>Cornell University</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/ahmedheakl/Guaranteed-Guess"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://huggingface.co/collections/ahmedheakl/guaranteed-guessing-67f7c4f7bf3b9bcf174ecab7"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Dataset</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://huggingface.co/collections/ahmedheakl/guaranteed-guessing-67f7c4f7bf3b9bcf174ecab7" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-download"></i>
                                        </span>
                                        <span>Models</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <figure class="image">
                    <img src="static\images\gg-main-v6_page-0001.jpg" alt="GG System Overview">
                </figure>
                <h2 class="subtitle has-text-centered">
                    <span class="gg">GG (Guaranteed Guess)</span> is the first assembly-to-assembly transpiler that
                    combines LLM-based translation with rigorous software testing to transpile x86 binaries into 
                    efficient ARM and RISC-V equivalents with testing guarantees.
                </h2>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            The hardware ecosystem is rapidly evolving, with increasing interest in translating low-level
                            programs across different instruction set architectures (ISAs) in a quick, flexible, and correct
                            way to enhance the portability and longevity of existing code. A particularly challenging class
                            of this transpilation problem is translating between complex- (CISC) and reduced- (RISC)
                            hardware architectures, due to fundamental differences in instruction complexity, memory
                            models, and execution paradigms.
                        </p>
                        <p>
                            In this work, we introduce <span class="gg">GG (Guaranteed Guess)</span>, an ISA-centric transpilation pipeline that
                            combines the translation power of pre-trained large language models (LLMs) with the rigor
                            of established software testing constructs. Our method generates candidate translations using
                            an LLM from one ISA to another, and embeds such translations within a software-testing
                            framework to build quantifiable confidence in the translation. We evaluate our <span class="gg">GG</span> approach
                            over two diverse datasets, enforce high code coverage (<b>>98%</b>) across unit tests, and
                            achieve functional/semantic correctness of <b>99%</b> on HumanEval programs and <b>49%</b> on
                            BringupBench programs, respectively. Further, we compare our approach to the state-of-the-art
                            Rosetta 2 framework on Apple Silicon, showcasing <b>1.73×</b> faster runtime performance,
                            <b>1.47×</b> better energy efficiency, and <b>2.41×</b> better memory usage for our transpiled code,
                            demonstrating the effectiveness of <span class="gg">GG</span> for real-world CISC-to-RISC translation tasks.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Key Contributions. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Key Contributions</h2>
                    <div class="content has-text-justified">
                        <ul style="font-size: 1.1em; line-height: 1.8;">
                            <li><strong>First CISC-to-RISC Transpiler:</strong> We introduce GG, the first CISC-to-RISC transpiler built via a custom-trained, architecture-aware LM achieving a test accuracy of 99.39% on ARMv8 and 89.93% on RISC-V64.</li>
                            
                            <li><strong>Testing-Driven Validation:</strong> A methodology to measure and build confidence into transpilation output via software testing approaches ("guaranteeing" the guess), including detailed analysis of correctness, errors, and hallucinations.</li>
                            
                            <li><strong>Hardware-Informed Design:</strong> An in-depth analysis into the inner workings of our transpiler, including hardware-informed design decisions to best train an accurate LLM model for assembly transpilation.</li>
                            
                            <li><strong>Real-World Case Study:</strong> We perform a case-study using our transpiler in a real-world setting, by comparing it directly to Apple Rosetta's x86 to ARM virtualization engine. Results show that GG's generated assembly achieves 1.73x runtime speedup while delivering 1.47x better energy efficiency and 2.41x memory efficiency.</li>
                        </ul>
                    </div>
                </div>
            </div>
            <!--/ Key Contributions. -->
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Training Data and Methodology -->
            <div class="columns is-centered">
                <div class="column">
                    <h2 class="title is-3">Training Data and Methodology</h2>
                    <div class="content has-text-justified">
                        <p>
                            GG is trained on 1.32M samples derived from AnghaBench (1M programs) and The StackV2 (306k programs),
                            compiled to both x86 (CISC) and ARM/RISC-V (RISC) targets under optimization levels -O0 and -O2
                            to expose models to both semantically transparent and performance-optimized binaries.
                        </p>
                        <p>
                            The training process uses DeepSeek-Coder and Qwen2.5-Coder as base models, with specialized 
                            tokenizer extensions for assembly opcodes and registers, RoPE extrapolation for longer context, 
                            and beam search decoding for improved accuracy.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Training Data -->
            
            <!-- Evaluation Benchmarks -->
            <div class="columns is-centered">
                <div class="column">
                    <h2 class="title is-3">Evaluation Benchmarks</h2>
                    <div class="content has-text-justified">
                        <p>
                            We evaluate GG using two complementary benchmarks: HumanEval-C with 164 programming problems
                            and BringUpBench with 65 bare-metal programs (85-5751 lines of code), providing comprehensive
                            coverage from isolated functions to full project structures with internal libraries.
                        </p>
                        <figure class="image">
                            <img src="static\images\token_dist_page-0001.jpg" alt="Token Counts by ISA and Benchmark" class="pipeline-image">
                        </figure>
                    </div>
                </div>
            </div>
            <!--/ Evaluation Benchmarks -->

            <!-- Results and Performance -->
            <div class="columns is-centered">
                <div class="column">
                    <h2 class="title is-3">Results and Performance</h2>

                    <h3 class="title is-4">Transpilation Accuracy</h3>
                    <div class="content has-text-justified">
                        <p>
                            GG models significantly outperform all baseline models across different architectures and optimization levels.
                            Most baseline models achieve 0% accuracy, highlighting the unique difficulty of low-level ISA translation.
                        </p>
                    </div>

                    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth results-table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>ARMv5 (-O0)</th>
                                <th>ARMv8 (-O0)</th>
                                <th>ARMv8 (-O2)</th>
                                <th>BringupBench (-O0)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>GPT-4o</td>
                                <td>8.48%</td>
                                <td>10.3%</td>
                                <td>4.24%</td>
                                <td>1.54%</td>
                            </tr>
                            <tr>
                                <td>Qwen2.5-Coder-1.5B</td>
                                <td>0%</td>
                                <td>0%</td>
                                <td>0%</td>
                                <td>0%</td>
                            </tr>
                            <tr>
                                <td>StarCoder2-3B</td>
                                <td>0%</td>
                                <td>0%</td>
                                <td>0%</td>
                                <td>0%</td>
                            </tr>
                            <tr>
                                <td>GG-DeepSeek-1.3B</td>
                                <td>79.25%</td>
                                <td>75.15%</td>
                                <td>10.3%</td>
                                <td>3.08%</td>
                            </tr>
                            <tr>
                                <td>GG-0.5B</td>
                                <td>90.85%</td>
                                <td>86.06%</td>
                                <td>25.45%</td>
                                <td>27.69%</td>
                            </tr>
                            <tr>
                                <td class="has-text-weight-bold">GG-1.5B</td>
                                <td class="has-text-weight-bold">93.71%</td>
                                <td class="has-text-weight-bold">99.39%</td>
                                <td class="has-text-weight-bold">45.12%</td>
                                <td class="has-text-weight-bold">49.23%</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3 class="title is-4">Real-World Performance vs Rosetta 2</h3>
                    <div class="content has-text-justified">
                        <p>
                            We conducted a real-world study on Apple M2 Pro comparing GG against Rosetta 2 across
                            execution time, CPU energy, and memory usage. GG achieves near-native performance while
                            significantly outperforming Rosetta 2 across all metrics.
                        </p>
                    </div>

                    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth results-table">
                        <thead>
                            <tr>
                                <th>Metric</th>
                                <th>Rosetta 2</th>
                                <th>GG (Ours)</th>
                                <th>Native</th>
                                <th>Improvement</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Execution Time (ms)</td>
                                <td>13.94</td>
                                <td>8.03</td>
                                <td>7.39</td>
                                <td class="has-text-weight-bold">1.73× faster</td>
                            </tr>
                            <tr>
                                <td>CPU Energy (J)</td>
                                <td>7.50</td>
                                <td>5.09</td>
                                <td>5.07</td>
                                <td class="has-text-weight-bold">1.47× better</td>
                            </tr>
                            <tr>
                                <td>RAM Usage (MB)</td>
                                <td>2.49</td>
                                <td>1.03</td>
                                <td>1.03</td>
                                <td class="has-text-weight-bold">2.41× better</td>
                            </tr>
                        </tbody>
                    </table>

                    <h3 class="title is-4">Ablation Study</h3>
                    <div class="content has-text-justified">
                        <p>
                            Our ablation study shows incremental improvements from each component, with data scaling
                            providing the biggest leap and architectural choices compounding gains toward near-perfect accuracy.
                        </p>
                    </div>

                    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth results-table">
                        <thead>
                            <tr>
                                <th>Component</th>
                                <th>ARMv8 Accuracy</th>
                                <th>Impact (Δ)</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Qwen2.5-Coder Baseline</td>
                                <td>0%</td>
                                <td>–</td>
                            </tr>
                            <tr>
                                <td>+ 1M AnghaBench</td>
                                <td>93.94%</td>
                                <td>+93.94%</td>
                            </tr>
                            <tr>
                                <td>+ 0.3M Stackv2</td>
                                <td>95.38%</td>
                                <td>+1.44%</td>
                            </tr>
                            <tr>
                                <td>+ RoPE Extrapolation</td>
                                <td>97.14%</td>
                                <td>+1.76%</td>
                            </tr>
                            <tr>
                                <td>+ Extended Tokenizer</td>
                                <td>98.18%</td>
                                <td>+1.04%</td>
                            </tr>
                            <tr>
                                <td>+ 8 Beam Search</td>
                                <td>99.39%</td>
                                <td>+1.21%</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
            <!--/ Results -->

            <!-- ISA Similarity Analysis -->
            <div class="columns is-centered">
                <div class="column">
                    <h2 class="title is-3">ISA Similarity Analysis</h2>
                    <div class="content has-text-justified">
                        <p>
                            We observe a direct correlation between ISA similarity and transpilation accuracy.
                            ARMv8 exhibits the highest similarity to x86 (40.19%), followed by ARMv5 (25.09%) and RISC-V64 (21.41%),
                            directly correlating with model accuracy performance across these architectures.
                        </p>
                        <p>
                            Additionally, we analyze how compiler optimization levels affect opcode usage patterns in ARMv8.
                            At -O2 optimization, <code>mov</code> instructions become dominant (+14.8%), indicating more register 
                            reuse and reduced memory traffic, which makes the learning task more challenging for the model.
                        </p>
                        <figure class="image">
                            <img src="static\images\asm_chrf_similarity_score_page-0001.jpg" alt="Opcode Shift and CHRF Similarity Analysis" class="pipeline-image">
                        </figure>
                    </div>
                </div>
            </div>
            <!--/ ISA Similarity -->
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
<pre><code>@article{heakl2025guaranteed,
  title={Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees},
  author={Heakl, Ahmed and Hashmi, Sarim and Abi, Chaimaa and Lee, Celine and Mahmoud, Abdulrahman},
  journal={arXiv preprint},
  year={2025},
  note={MBZUAI, Cornell University}
}</code></pre>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="#" class="external-link">
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            Website template adapted from <a href="https://nerfies.github.io">Nerfies</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
</body>
</html>